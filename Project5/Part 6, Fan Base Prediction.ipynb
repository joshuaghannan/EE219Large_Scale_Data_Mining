{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "QJ9P1C1XmHW3",
    "outputId": "b13efa3c-3c3f-4c09-92f2-ba7a50e2accf"
   },
   "outputs": [],
   "source": [
    "# ########################################################\n",
    "\n",
    "# # If running with Google Colab\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "pMYNW7bIm_kz",
    "outputId": "179e423f-25b7-43ac-ace5-784285d6d1f6"
   },
   "outputs": [],
   "source": [
    "# ########################################################\n",
    "\n",
    "# # If running with Google Colab\n",
    "\n",
    "# !ls \"/content/gdrive/My Drive/Datasets/Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QwmoccnlmFeR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# training and Testing directories\n",
    "training_dir = os.path.join(\"Datasets\", \"Training\")\n",
    "testing_dir = os.path.join(\"Datasets\", \"Testing\")\n",
    "if not os.path.isdir(training_dir):\n",
    "    raise Exception(\"ERROR: training dataset not found\")\n",
    "if not os.path.isdir(testing_dir):\n",
    "    raise Exception(\"ERROR: testing dataset not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w4pJUGEDo8pV"
   },
   "outputs": [],
   "source": [
    "# ########################################################\n",
    "\n",
    "# # If running with Google Colab\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import sys\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "# from tqdm import tqdm\n",
    "# %matplotlib inline\n",
    "# plt.style.use('default')\n",
    "\n",
    "\n",
    "# import random\n",
    "# np.random.seed(42)\n",
    "# random.seed(42)\n",
    "\n",
    "# # Ignore warnings\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from pathlib import Path\n",
    "\n",
    "# training_dir = Path(\"/content/gdrive/My Drive/Datasets/Training\")\n",
    "# testing_dir = Path(\"/content/gdrive/My Drive/Datasets/Testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gIcYM82cmFeY"
   },
   "source": [
    "## Establish Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "h2HDYiPKmFea",
    "outputId": "dd47ff17-185a-4de6-b782-6c1c51bec698"
   },
   "outputs": [],
   "source": [
    "# iterate over all hashtag files \n",
    "for root, dirs, files in os.walk(training_dir, topdown=False):\n",
    "    for file in files:\n",
    "        print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jUswnDZVmFei"
   },
   "outputs": [],
   "source": [
    "# Look at the gopatriots dataset for testing\n",
    "# change to only_superbowl = ['superbowl'] for actual running\n",
    "\n",
    "only_superbowl = ['superbowl']\n",
    "only_gopatriots = ['gopatriots'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "ZhAGlAHDmFel",
    "outputId": "5a0c581d-27dc-4e16-afc1-561ff9c6f219"
   },
   "outputs": [],
   "source": [
    "# Testing with Full Size\n",
    "locations = []\n",
    "\n",
    "# iterate over all hashtag files \n",
    "for root, dirs, files in os.walk(training_dir, topdown=False):\n",
    "    for file in files:\n",
    "        filename = os.path.splitext(file)[0].replace('tweets_#', '')\n",
    "          \n",
    "        # CHANGE TO only_superbowl for final submission\n",
    "        # Only Look at the gopatriots Data file for testing\n",
    "        if not filename in only_superbowl:\n",
    "#         if not filename in only_gopatriots:\n",
    "            continue\n",
    "        \n",
    "        print('Parsing {}...'.format(filename))\n",
    "        \n",
    "        # only extracting specific features from the tweet json objects\n",
    "        citation_dates = []\n",
    "        \n",
    "        # open the file and read all lines:\n",
    "        with open(os.path.join(root, file), \"r\", encoding=\"utf-8\") as hashtag:\n",
    "            # read line-by-line\n",
    "            for line in hashtag:\n",
    "                json_obj = json.loads(line)\n",
    "                \n",
    "                # get citation date\n",
    "                citation_date = json_obj['citation_date']\n",
    "                citation_dates.append(citation_date)\n",
    "                \n",
    "                # get locations \n",
    "                location = json_obj['tweet']['user']['location']\n",
    "                locations.append(location)\n",
    "        \n",
    "        # processing citation feature\n",
    "        print('\\t'+'-'*10)\n",
    "        citation_dates = np.array(citation_dates)\n",
    "        print('\\tnumber of tweets in period: {}'.format(len(citation_dates)))\n",
    "        min_date = np.min(citation_dates)\n",
    "        max_date = np.max(citation_dates)\n",
    "\n",
    "        # processing all locations\n",
    "        print('\\t'+'-'*10)\n",
    "        print('\\tnumber of locations in {} dataset: {}'.format(filename, len(locations)))\n",
    "        \n",
    "        print('\\t'+'-'*10)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iPcqVrtKmFeq",
    "outputId": "0b3d45c5-d9a7-4d05-8f3a-6d151a8f3049"
   },
   "outputs": [],
   "source": [
    "unique_locations = []\n",
    "\n",
    "for location in locations:\n",
    "    if location in unique_locations: # Avoid duplicates\n",
    "        continue\n",
    "\n",
    "    unique_locations.append(location)\n",
    "    \n",
    "print('number of unique locations is: {}'.format(len(unique_locations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KOpwEbFumFew"
   },
   "source": [
    "## Determine if in MA or WA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "Dy3gtiChmFex",
    "outputId": "38f7c7f9-dfc4-47f8-c261-84684309dd7b"
   },
   "outputs": [],
   "source": [
    "# Define Locations\n",
    "\n",
    "MA_WA = [' MA',' WA', 'Massachusetts', 'Washington', 'Boston', 'Seattle'] # Look for all possible MA and WA matches\n",
    "# NOTE: added 'space' before MA and WA to avoid problems such as IOWA; Could do this differently\n",
    "\n",
    "all_MA_WA = [location for location in unique_locations if any(place in location for place in MA_WA)] # Create list of all places in MA and WA\n",
    "\n",
    "DC = ['DC', 'D.C.', 'D.C']\n",
    "\n",
    "all_MA_WA_no_DC = [location for location in all_MA_WA if not any(place in location for place in DC)] # remove DC and D.C.\n",
    "\n",
    "MA = [' MA', 'Massachusetts', 'Boston'] # Get just locations in Massachusetts\n",
    "WA = [' WA', 'Washington', 'Seattle'] # Get just locations in Washington\n",
    "\n",
    "only_MA = [location for location in all_MA_WA_no_DC if any(place in location for place in MA)] # Get just locations in Massachusetts\n",
    "only_WA = [location for location in all_MA_WA_no_DC if any(place in location for place in WA)] # Get just locations in Washington\n",
    "\n",
    "print('number of unique locations in MA or WA : {}'.format(len(all_MA_WA)))\n",
    "print('-'*10)\n",
    "print('number of unique locations in MA or WA after removing DC: {}'.format(len(all_MA_WA_no_DC)))\n",
    "print('-'*10)\n",
    "print('number of locations in MA: {}'.format(len(only_MA)))\n",
    "print('-'*10)\n",
    "print('number of locations in WA: {}'.format(len(only_WA)))\n",
    "\n",
    "# print('-'*10)\n",
    "# print('Locations in MA and WA: ','\\n', *all_MA_WA_no_DC, sep = \"\\n\")\n",
    "# print('-'*10)\n",
    "# print('Locations in MA: ','\\n', *only_MA, sep = \"\\n\")\n",
    "# print('-'*10)\n",
    "# print('Locations in WA: ','\\n', *only_WA, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HM1l4-N-mFe3"
   },
   "source": [
    "## Extract all tweets from WA or MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "eXoFUkkxmFe4",
    "outputId": "d89c5deb-71c7-45ab-9f95-894ad088088e"
   },
   "outputs": [],
   "source": [
    "# Extract all tweets from WA or MA\n",
    "\n",
    "# Testing with Fullsize File\n",
    "\n",
    "# Store textual data and location labels 0 if MA 1 if WA \n",
    "tweet_textual_data = [] \n",
    "tweet_location_labels = []\n",
    "\n",
    "# Initialize counting variables to keep track of number of tweets from MA and WA\n",
    "num_tweets_MA = 0\n",
    "num_tweets_WA = 0\n",
    "\n",
    "for root, dirs, files in os.walk(training_dir, topdown=False):\n",
    "    for file in files:\n",
    "        filename = os.path.splitext(file)[0].replace('tweets_#', '')\n",
    "          \n",
    "        # CHANGE TO only_superbowl for final submission\n",
    "        # Only Look at the gopatriots Data file for testing\n",
    "        if not filename in only_superbowl:\n",
    "#         if not filename in only_gopatriots:\n",
    "            continue\n",
    "        \n",
    "        print('Parsing {}...'.format(filename))\n",
    "        \n",
    "        # only extracting specific features from the tweet json objects\n",
    "        \n",
    "        # open the file and read all lines:\n",
    "        with open(os.path.join(root, file), \"r\", encoding=\"utf-8\") as hashtag:\n",
    "            # read line-by-line\n",
    "            for line in hashtag:\n",
    "                json_obj = json.loads(line)\n",
    "                \n",
    "                # get tweets that are only in MA and WA (not DC)\n",
    "                location = json_obj['tweet']['user']['location']\n",
    "                \n",
    "                if not any(MAWA in location for MAWA in all_MA_WA_no_DC):\n",
    "                    continue\n",
    "                \n",
    "                if any (loc in location for loc in only_MA):\n",
    "                    # get textual data\n",
    "                    text = json_obj['tweet']['text'] \n",
    "                    tweet_textual_data.append(text)\n",
    "                    \n",
    "                    # add location is in MA (0)\n",
    "                    tweet_location_labels.append(0)\n",
    "                    \n",
    "                    num_tweets_MA += 1\n",
    "                    \n",
    "                if any (loc in location for loc in only_WA):\n",
    "                    if any (loc in location for loc in DC): # Check if contains DC\n",
    "                        continue\n",
    "                        \n",
    "                    # get textual data\n",
    "                    text = json_obj['tweet']['text'] \n",
    "                    tweet_textual_data.append(text)\n",
    "                \n",
    "                    # add location is in WA (1)\n",
    "                    tweet_location_labels.append(1)\n",
    "                                         \n",
    "                    num_tweets_WA += 1    \n",
    "                    \n",
    "        # process textual data\n",
    "        print('\\t'+'-'*10)\n",
    "        print('\\tNumber of texts in {} dataset: {}'.format(filename, len(tweet_textual_data)))\n",
    "        \n",
    "        # Process MA and WA locations\n",
    "        print('\\t'+'-'*10)\n",
    "        print('\\tNumber of tweets from MA and WA is: {}'.format(len(tweet_location_labels)))\n",
    "        \n",
    "        print('\\t'+'-'*10)\n",
    "        print('\\tNumber of tweets from MA is: ', num_tweets_MA)\n",
    "        \n",
    "        print('\\t'+'-'*10)\n",
    "        print('\\tNumber of tweets from WA is: ', num_tweets_WA)\n",
    "        \n",
    "#         print('\\t'+'-'*10)\n",
    "#         print('\\tTextual data looks like: ', *tweet_textual_data, sep = \"\\n\")\n",
    "        \n",
    "#         print('\\t'+'-'*10)\n",
    "#         print('\\tLabels look like: ', tweet_location_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_t7DAcCmFe_"
   },
   "outputs": [],
   "source": [
    "tweet_location_labels = np.asarray(tweet_location_labels)\n",
    "\n",
    "class_names = ['Massachusetts', \"Washington\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "colab_type": "code",
    "id": "SGDQCGcMmFfG",
    "outputId": "b86862e0-5052-4f23-ff3c-e9b578163a71"
   },
   "outputs": [],
   "source": [
    "# Plot distribution of tweets per locations\n",
    "\n",
    "plt.bar([0,1],[num_tweets_MA, num_tweets_WA])\n",
    "plt.xticks([0,1], class_names)\n",
    "plt.xlabel('Number of Tweets')\n",
    "plt.title(\"Tweets Per Location\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oXUy2eG3mFfK"
   },
   "source": [
    "## Define training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oLivBf-wmFfL"
   },
   "outputs": [],
   "source": [
    "# Define training and testing datasets\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.asarray(tweet_textual_data)\n",
    "y = tweet_location_labels\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle = True)\n",
    "\n",
    "for trainset, testset in kf.split(X):\n",
    "    X_train, X_test = X[trainset], X[testset]\n",
    "    y_train, y_test = y[trainset], y[testset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e3qfPCXRmFfO"
   },
   "source": [
    "## Lemmatization & Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "JLX3tEz0mFfQ",
    "outputId": "6008687d-f704-426f-8917-ffbdefd9c8e9"
   },
   "outputs": [],
   "source": [
    "# Lemmatization functions used by CountVectorizer\n",
    "\n",
    "# The lemmatizer is actually pretty complicated, it needs Parts of Speech (POS) tags\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "# nltk.download('punkt')#, if you need \"tokenizers/punkt/english.pickle\", choose it\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN': 'n', 'JJ': 'a',\n",
    "                  'VB': 'v', 'RB': 'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n'\n",
    "\n",
    "wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "def lemmatize_sent(list_word):\n",
    "    # Text input is string, returns array of lowercased strings(words).\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(list_word)]\n",
    "\n",
    "def isfloat(string):\n",
    "    try:\n",
    "        float(string)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def stem_rmv_punc(doc):\n",
    "    return (word for word in lemmatize_sent(analyzer(doc)) if not isfloat(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xN6sZ_gnmFfT"
   },
   "outputs": [],
   "source": [
    "# Push lemmatized documents through CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(min_df=3, analyzer=stem_rmv_punc, stop_words='english')\n",
    "\n",
    "# do for training\n",
    "X_lemmatized_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "# do for testing\n",
    "X_lemmatized_test_counts = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYnNGp1ymFfX"
   },
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "YkkQZbk4mFfY",
    "outputId": "a80014b9-44ce-4610-bc2f-9bf69941f506"
   },
   "outputs": [],
   "source": [
    "# Report shapes of TF-IDF matrices\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# do for training\n",
    "X_lemmatized_train_tfidf = tfidf_transformer.fit_transform(X_lemmatized_train_counts)\n",
    "print(X_lemmatized_train_tfidf.shape)\n",
    "\n",
    "# do for testing\n",
    "X_lemmatized_test_tfidf = tfidf_transformer.transform(X_lemmatized_test_counts)\n",
    "print(X_lemmatized_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HNKSHgMmmFfc"
   },
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BIywEPOKmFfd"
   },
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "NeQYWPUUmFff",
    "outputId": "520513ab-ccdc-4bac-c55a-0307472ab217"
   },
   "outputs": [],
   "source": [
    "# Perform NMF\n",
    "\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "model = NMF(n_components=50, init='random', random_state=42)\n",
    "W_nmf_train_reduced = model.fit_transform(X_lemmatized_train_tfidf)\n",
    "H_nmf_train_reduced = model.components_\n",
    "\n",
    "print(W_nmf_train_reduced.shape)\n",
    "print(H_nmf_train_reduced.shape)\n",
    "\n",
    "W_nmf_test_reduced = model.transform(X_lemmatized_test_tfidf)\n",
    "H_nmf_test_reduced = model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YpSHMrwKmFfl"
   },
   "source": [
    "### LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "jvWL54uxmFfn",
    "outputId": "12d18c9f-223c-4d1e-87e3-a31b6fe63571"
   },
   "outputs": [],
   "source": [
    "# Perform LSI using the truncated SVD\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "X_lsi_train_reduced = svd.fit_transform(X_lemmatized_train_tfidf)\n",
    "Y_lsi_train_reduced = svd.components_\n",
    "print(X_lsi_train_reduced.shape)\n",
    "print(svd.components_.shape)\n",
    "\n",
    "X_lsi_test_reduced = svd.transform(X_lemmatized_test_tfidf)\n",
    "Y_lsi_test_reduced = svd.components_\n",
    "print(X_lsi_train_reduced.shape)\n",
    "print(svd.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "up4ZfemzmFfr",
    "outputId": "852daec0-8179-45a9-c47b-5107ac5b7213"
   },
   "outputs": [],
   "source": [
    "# Compare LSI and NMF (Training)\n",
    "\n",
    "nmf_val = np.linalg.norm(X_lemmatized_train_tfidf - np.matmul(W_nmf_train_reduced, H_nmf_train_reduced), 'fro')**2\n",
    "lsi_val = np.linalg.norm(X_lemmatized_train_tfidf - np.matmul(X_lsi_train_reduced, Y_lsi_train_reduced), 'fro')**2\n",
    "\n",
    "print('Training NMF: ', nmf_val)\n",
    "print('Training LSI: ', lsi_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "DHihyLq8mFfv",
    "outputId": "a4784d36-bcc1-4e66-bf5a-964431da9226"
   },
   "outputs": [],
   "source": [
    "# Compare LSI and NMF (Testing)\n",
    "\n",
    "nmf_val = np.linalg.norm(X_lemmatized_test_tfidf - np.matmul(W_nmf_test_reduced, H_nmf_test_reduced), 'fro')**2\n",
    "lsi_val = np.linalg.norm(X_lemmatized_test_tfidf - np.matmul(X_lsi_test_reduced, Y_lsi_test_reduced), 'fro')**2\n",
    "\n",
    "print('Testing NMF: ', nmf_val)\n",
    "print('Testing LSI: ', lsi_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tePJsNTLmFfx"
   },
   "source": [
    "## Define Confusion Matrix Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VGHhUIaxmFfy"
   },
   "outputs": [],
   "source": [
    "# Taken from scikit-learn website: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cECQh2fumFf0"
   },
   "source": [
    "## Classifier Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DBaFYJffmFf2"
   },
   "source": [
    "### 1. SVM with Hard and Soft Margin, (LSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AAreM2hmFf3"
   },
   "outputs": [],
   "source": [
    "# Training 2 linear SVMs using LSI\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# hard margin\n",
    "gamma_1 = 1000\n",
    "clf_svc_1 = LinearSVC(C=gamma_1,max_iter=100000).fit(X_lsi_train_reduced, y_train)\n",
    "predicted_svc_1 = clf_svc_1.predict(X_lsi_test_reduced)\n",
    "\n",
    "# using max_iter=100000 because otherwise the hard margin classifier does not converge\n",
    "\n",
    "#soft margin\n",
    "gamma_2 = 0.0001\n",
    "clf_svc_2 = LinearSVC(C=gamma_2,max_iter=100000).fit(X_lsi_train_reduced, y_train)\n",
    "predicted_svc_2 = clf_svc_2.predict(X_lsi_test_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mXnBDvsxmFf6"
   },
   "source": [
    "#### 1.1 SVM Hard Margin Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1127
    },
    "colab_type": "code",
    "id": "zRlgLbc3mFf7",
    "outputId": "1ff166c0-194e-4108-93f0-38f569ed7712"
   },
   "outputs": [],
   "source": [
    "# Find confusion matrix, accuracy, precision-recall, and F-1 scores for the hard margin\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# print('Confusion matrix for linear SVM hard margin: \\n', confusion_matrix(twenty_test_binary_labels, predicted_svc_1))\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted_svc_1), classes=class_names)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted_svc_1), classes=class_names, normalize=True)\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy for linear SVM hard margin: ', accuracy_score(y_test, predicted_svc_1))\n",
    "\n",
    "# Average precision-recall score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# print('Average precision-recall score:', average_precision_score(twenty_test.target, predicted))\n",
    "print('Precision score for linear SVM hard margin: ', precision_score(y_test, predicted_svc_1))\n",
    "print('Recall score for linear SVM hard margin: ', recall_score(y_test, predicted_svc_1))\n",
    "\n",
    "# F-1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F-1 score for linear SVM hard margin:', f1_score(y_test, predicted_svc_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "colab_type": "code",
    "id": "b_ZJIxm1mFf_",
    "outputId": "bcf9c016-d03a-452d-d037-93e760a178a2"
   },
   "outputs": [],
   "source": [
    "# ROC curve for hard margin SVM\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "score_svc_1 = clf_svc_1.decision_function(X_lsi_test_reduced)\n",
    "fpr_svc_1, tpr_svc_1, thresholds_svc_1 = roc_curve(y_test, score_svc_1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_svc_1, tpr_svc_1)\n",
    "plt.title('ROC curve for hard margin linear SVM')\n",
    "plt.text(0.5, 0.1, 'area under curve = %0.4f' % roc_auc_score(y_test, score_svc_1))\n",
    "plt.xlabel('false positive rate for hard margin linear SVM')\n",
    "plt.ylabel('true positive rate for hard margin linear SVM')\n",
    "plt.xlim(left=-0.02)\n",
    "plt.ylim(top=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IEY4uQbbmFgD"
   },
   "source": [
    "#### 1.2 SVM Soft Margin Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1127
    },
    "colab_type": "code",
    "id": "j0bZ8fbQmFgE",
    "outputId": "9a3267f9-d833-48bb-c329-fa8158aedd16"
   },
   "outputs": [],
   "source": [
    "# Find confusion matrix, accuracy, precision-recall, and F-1 scores for the soft margin\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# print('Confusion matrix for linear SVM soft margin: \\n', confusion_matrix(twenty_test_binary_labels, predicted_svc_2))\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted_svc_2), classes=class_names)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted_svc_2), classes=class_names, normalize=True)\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy for linear SVM soft margin: ', accuracy_score(y_test, predicted_svc_2))\n",
    "\n",
    "# Average precision-recall score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# print('Average precision-recall score:', average_precision_score(twenty_test.target, predicted))\n",
    "print('Precision score for linear SVM soft margin: ', precision_score(y_test, predicted_svc_2))\n",
    "print('Recall score for linear SVM soft margin: ', recall_score(y_test, predicted_svc_2))\n",
    "\n",
    "# F-1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F-1 score for linear SVM soft margin:', f1_score(y_test, predicted_svc_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "colab_type": "code",
    "id": "4NqVCEgKmFgH",
    "outputId": "35592e01-6600-463e-fc9d-e91e97152671"
   },
   "outputs": [],
   "source": [
    "# ROC curve for soft margin SVM\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "score_svc_2 = clf_svc_2.decision_function(X_lsi_test_reduced)\n",
    "fpr_svc_2, tpr_svc_2, thresholds_svc_2 = roc_curve(y_test, score_svc_2)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_svc_2, tpr_svc_2)\n",
    "plt.title('ROC curve for soft margin linear SVM')\n",
    "plt.text(0.5, 0.1, 'area under curve = %0.4f' % roc_auc_score(y_test, score_svc_2))\n",
    "plt.xlabel('false positive rate for soft margin linear SVM')\n",
    "plt.ylabel('true positive rate for soft margin linear SVM')\n",
    "plt.xlim(left=-0.02)\n",
    "plt.ylim(top=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K6ZM_iPMmFgM"
   },
   "source": [
    "###  2. Logistic Regression without Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ex5FmJQYmFgN"
   },
   "outputs": [],
   "source": [
    "# Train an unregularized logistic regression classifier.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# To be unregularized, we make the inverse of the regularization strength C \n",
    "# to be large to approximate an unregularized classifier.\n",
    "clf = LogisticRegression(random_state=42, C=500, max_iter=100, solver='lbfgs').fit(X_lsi_train_reduced, y_train)\n",
    "\n",
    "# score = clf.decision_function(X_lsi_test_reduced)\n",
    "predicted = clf.predict(X_lsi_test_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJQczcrHmFgQ"
   },
   "source": [
    "#### 2.1 Logistic Regression without Regularization Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1127
    },
    "colab_type": "code",
    "id": "PW3lMrOtmFgR",
    "outputId": "70fcb62b-3062-46c9-9de6-cd2f1f5a8b13"
   },
   "outputs": [],
   "source": [
    "# Find confusion matrix, accuracy, precision-recall, and F-1 scores\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# print('Confusion matrix: \\n', confusion_matrix(twenty_test_binary_labels, predicted))\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted), classes=class_names)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted), classes=class_names, normalize=True)\n",
    "plt.show()\n",
    "\n",
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, predicted))\n",
    "\n",
    "# Average precision-recall score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# print('Average precision-recall score:', average_precision_score(twenty_test.target, predicted))\n",
    "print('Precision score: ', precision_score(y_test, predicted))\n",
    "print('Recall score: ', recall_score(y_test, predicted))\n",
    "\n",
    "# F-1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print('F-1 score:', f1_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "colab_type": "code",
    "id": "-yF1u3zgmFgV",
    "outputId": "21a95477-91fc-4acb-a12e-19ca9026a552"
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "score = clf.decision_function(X_lsi_test_reduced)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, score)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.text(0.5, 0.1, 'area under curve = %0.4f' % roc_auc_score(y_test, score))\n",
    "plt.title('ROC curve for unregularized logistic regression')\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlim(left=-0.02)\n",
    "plt.ylim(top=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "30z9e9o6mFgZ"
   },
   "source": [
    "### 3. Logistic Regression With L1 & L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1148
    },
    "colab_type": "code",
    "id": "QhYz6HFhmFga",
    "outputId": "821aaf16-5000-4b15-c9a5-5e565b9b64e9"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Define training and testing data sets\n",
    "X_train = X_lsi_train_reduced\n",
    "X_test = X_lsi_test_reduced\n",
    "\n",
    "# Define regularization strength values here\n",
    "REG_STRENGTH_OPTIONS = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "# Determine regulation strength for L1 regulation\n",
    "clf_L1 = LogisticRegressionCV(random_state=42, Cs=REG_STRENGTH_OPTIONS, cv=5, penalty='l1', scoring='accuracy', solver = 'liblinear').fit(X_train, y_train)\n",
    "l1_reg_strength = 1/clf_L1.C_ # Regulization strength is inverse of optimal Cs\n",
    "predicted_L1 = clf_L1.predict(X_test)\n",
    "\n",
    "# Display L1 Stats\n",
    "print('Optimal regularization strength for L1 Regulation: ', l1_reg_strength)\n",
    "print('Accuracy with L1 Regulation for L1 Regulation: ', clf_L1.score(X_test, y_test))\n",
    "print('Average precision-recall score for L1 Regulation:', average_precision_score(y_test, predicted_L1))\n",
    "print('Precision score for L1 Regulation: ', precision_score(y_test, predicted_L1))\n",
    "print('Recall score for L1 Regulation: ', recall_score(y_test, predicted_L1))\n",
    "print('F-1 score for L1 Regulation:', f1_score(y_test, predicted_L1))\n",
    "\n",
    "# L1 ROC Curve\n",
    "score_L1 = clf_L1.decision_function(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, score_L1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve for L1 Regularized Logistic Regression')\n",
    "plt.text(0.5, 0.1, 'area under curve = %0.4f' % roc_auc_score(y_test, score_L1))\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlim(left=-0.01)\n",
    "plt.show()\n",
    "\n",
    "# Determine regulation strength for L2 regulation\n",
    "clf_L2 = LogisticRegressionCV(random_state=42, Cs=REG_STRENGTH_OPTIONS, cv=5, penalty='l2', scoring='accuracy', solver = 'liblinear').fit(X_train, y_train)\n",
    "L2_reg_strength = 1/clf_L2.C_ # Regulization strength is inverse of optimal Cs\n",
    "predicted_L2 = clf_L2.predict(X_test)\n",
    "\n",
    "# Display L2 Stats\n",
    "print('\\nOptimal regularization strength for L2 regulation: ', L2_reg_strength)\n",
    "print('Accuracy with L2 Regulation: ', clf_L2.score(X_test, y_test))\n",
    "print('Average precision-recall score for L2 Regulation:', average_precision_score(y_test, predicted_L2))\n",
    "print('Precision score for L2 Regulation: ', precision_score(y_test, predicted_L2))\n",
    "print('Recall score for L2 Regulation: ', recall_score(y_test, predicted_L2))\n",
    "print('F-1 score for L2 Regulation:', f1_score(y_test, predicted_L2))\n",
    "\n",
    "# L2 ROC Curve\n",
    "score_L2 = clf_L2.decision_function(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, score_L2)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve for L2 Regularized Logistic Regression')\n",
    "plt.text(0.5, 0.1, 'area under curve = %0.4f' % roc_auc_score(y_test, score_L2))\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlim(left=-0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dUT8AtpWmFgc"
   },
   "source": [
    "### 4. Naive Bayes Gaussian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYuPrkbKmFgd"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1599
    },
    "colab_type": "code",
    "id": "6J24sHGcmFgf",
    "outputId": "f3415f8a-22fa-44da-e13d-d7d1c934d2b4"
   },
   "outputs": [],
   "source": [
    "# Generate stats for GaussianNB using LSI for reduction\n",
    "\n",
    "# Define training and testing data sets\n",
    "X_train = X_lsi_train_reduced\n",
    "X_test = X_lsi_test_reduced\n",
    "\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted), classes=class_names)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plot_confusion_matrix(confusion_matrix(y_test, predicted), classes=class_names, normalize=True)\n",
    "plt.show()\n",
    "\n",
    "# Display GNB Stats\n",
    "print('Accuracy for Gaussian NB from LSI: ', clf.score(X_test, y_test))\n",
    "print('Average precision-recall score for Gaussian NB from LSI:', average_precision_score(y_test, predicted))\n",
    "print('Precision score for Gaussian NB from LSI: ', precision_score(y_test, predicted))\n",
    "print('Recall score for Gaussian NB from LSI: ', recall_score(y_test, predicted))\n",
    "print('F-1 score for Gaussian NB from LSI:', f1_score(y_test, predicted))\n",
    "\n",
    "# GNB ROC Curve\n",
    "prob_score = clf.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob_score[:, 1])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title('ROC curve for Gaussian NB from LSI')\n",
    "plt.text(0.5, 0.1, 'area under curve = %0.4f' % roc_auc_score(y_test, prob_score[:, 1]))\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.xlim(left=-0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nzXoEpUEmFgh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPrRslP1mFgj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of Part 6, Fan Base Prediction.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
